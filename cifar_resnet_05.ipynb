{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f04f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Subset\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42##设置随机种子使结果可复现\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "label_map = {\n",
    "    'airplane': 0,\n",
    "    'automobile': 1,\n",
    "    'bird': 2,\n",
    "    'cat': 3,\n",
    "    'deer': 4,\n",
    "    'dog': 5,\n",
    "    'frog': 6,\n",
    "    'horse': 7,\n",
    "    'ship': 8,\n",
    "    'truck': 9\n",
    "}##标签和数字的一一映射\n",
    "\n",
    "class MyCIFAR10Dataset(Dataset):##定义数据类（labels从.csv文件中获取）\n",
    "    def __init__(self, img_dir, csv_path, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id=self.labels.iloc[idx,0]\n",
    "        label_str=self.labels.iloc[idx,1]\n",
    "        label=label_map[label_str]\n",
    "        img_path = os.path.join(self.img_dir,f'{img_id}'+'.png')\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    def reset_transform(self,new_transform):\n",
    "        self.transform = new_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13836c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r\"C:\\Users\\Lenovo\\AI\\project\\data\\train\"\n",
    "csv_path = r\"C:\\Users\\Lenovo\\AI\\project\\data\\trainLabels.csv\"\n",
    "transform_for_stats=transforms.ToTensor()##需要从一小部分数据集里获得近似均值和标准差以定义transform_for_train，而定义数据集本身就需要transform，因此定义一个初始transform\n",
    "dataset_for_stats=MyCIFAR10Dataset(img_dir,csv_path,transform=transform_for_stats)\n",
    "def get_mean_std(dataset, ratio=0.01):##取一小部分数据集来近似获得均值和标准差以用于归一化\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=int(len(dataset) * ratio), shuffle=True, num_workers=0\n",
    "    )\n",
    "    train = iter(dataloader).__next__()[0]\n",
    "    mean = np.mean(train.numpy(), axis=(0, 2, 3))\n",
    "    std = np.std(train.numpy(), axis=(0, 2, 3))\n",
    "    return mean, std\n",
    "\n",
    "data_mean,data_std=get_mean_std(dataset_for_stats)\n",
    "transform_for_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_mean,\n",
    "                         std=data_std),\n",
    "])##对训练集数据增强\n",
    "transform_for_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_mean,\n",
    "                         std=data_std),\n",
    "])##对验证集仅归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = MyCIFAR10Dataset(img_dir, csv_path, transform=transform_for_train)\n",
    "dataset2 = MyCIFAR10Dataset(img_dir, csv_path, transform=transform_for_val)\n",
    "train_size=int(0.9*len(dataset1))\n",
    "val_size=len(dataset1)-train_size\n",
    "# 加种子确保可复现\n",
    "indices = list(range(len(dataset1)))\n",
    "train_indices, val_indices = random_split(indices, [train_size, val_size], generator=torch.Generator().manual_seed(seed))\n",
    "#构造子集（注意：不同 transform 绑定的是不同 dataset）\n",
    "trainset = Subset(dataset1, train_indices)\n",
    "valset   = Subset(dataset2, val_indices)\n",
    "train_dataloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=0)\n",
    "val_dataloader   = DataLoader(valset,   batch_size=50, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(num_classes):##在torchvision的resnet-18基础上稍加修改以适应小规模的CIFAR-10数据集\n",
    "    model = models.resnet18(weights=None) \n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()#去掉ResNet中原始的maxpool\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)#全连接层\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 10\n",
    "model = build_resnet(num_classes).to(device)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d37513",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)##正则化\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=60, eta_min=0)##余弦衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce033071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(losses, accuracies, label='Train'):\n",
    "    # 避免列表元素是float\n",
    "    losses = [float(x.cpu()) if isinstance(x, torch.Tensor) else float(x) for x in losses]\n",
    "    accuracies = [float(x.cpu()) if isinstance(x, torch.Tensor) else float(x) for x in accuracies]\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # 绘制 Loss 曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses, 'r-', label=f'{label} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{label} Loss')\n",
    "    plt.legend()\n",
    "    # 绘制 Accuracy 曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracies, 'b-', label=f'{label} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'{label} Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021afa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,criterion,optimizer,device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        ##参数更新\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ##累计正确预测个数与总数\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss/total,correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()  # 进入评估模式\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)  # 加总整个 batch 的 loss\n",
    "            _, preds = torch.max(outputs, 1)  # 获得预测类别\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss/total,correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_losses=[]\n",
    "train_accuracies=[]\n",
    "val_losses=[]\n",
    "val_accuracies=[]\n",
    "val_best_acc=0\n",
    "trigger_times=0##耐心值\n",
    "for epoch in range(num_epochs):\n",
    "    train_avg_loss,train_acc=train(model,train_dataloader,criterion,optimizer,device)\n",
    "    val_avg_loss,val_acc=evaluate(model,val_dataloader,criterion,device)\n",
    "    ##计算每个epoch后训练集和验证集的平均loss和accuracy\n",
    "    train_losses.append(train_avg_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_avg_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    if val_acc>val_best_acc:\n",
    "       torch.save(model.state_dict(), \"resnet_05.pth\")\n",
    "       val_best_acc=val_acc\n",
    "       trigger_times=0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times==7:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_avg_loss:.4f}, Accuracy: {train_acc*100:.2f}%\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_avg_loss:.4f}, Accuracy: {val_acc*100:.2f}%\")\n",
    "    scheduler.step()  # 更新学习率\n",
    "plot_training_progress(train_losses, train_accuracies,label='train')\n",
    "plot_training_progress(val_losses, val_accuracies,label='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform_for_val)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=50,shuffle=False,num_workers=0)\n",
    "net = build_resnet(10)\n",
    "net.load_state_dict(torch.load(r\"resnet_05.pth\"))\n",
    "net.eval()\n",
    "correct=0\n",
    "total=0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "with torch.no_grad():\n",
    "    for imgs,labels in test_dataloader:\n",
    "        imgs,labels = imgs.to(device),labels.to(device)\n",
    "        outputs = net(imgs)\n",
    "        _,predicted = torch.max(outputs,1)\n",
    "        total +=labels.size(0)\n",
    "        correct +=(predicted==labels).sum().item()\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7161131",
   "metadata": {},
   "outputs": [],
   "source": [
    "##预测测试集并保存结果（用于提交）\n",
    "\n",
    "\n",
    "#加载测试图片的文件夹\n",
    "test_image_dir = r\"C:\\Users\\Lenovo\\AI\\project\\data\\test\\test\"\n",
    "test_images = sorted(glob.glob(os.path.join(test_image_dir, \"*.png\")),\n",
    "                     key=lambda x: int(re.findall(r\"(\\d+)\", os.path.basename(x))[0]))#按数字顺序排序\n",
    "\n",
    "#设置标签映射（数字到字符串的映射）\n",
    "label_map_reverse = {v: k for k, v in label_map.items()}\n",
    "\n",
    "#定义transform，与训练时一致\n",
    "transform_for_test = transform_for_val\n",
    "\n",
    "#再次加载模型\n",
    "net = build_resnet(10)\n",
    "net.load_state_dict(torch.load(r\"resnet_05.pth\"))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "#预测\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for img_path in tqdm(test_images):\n",
    "        img = Image.open(img_path)\n",
    "        img = transform_for_test(img).unsqueeze(0).to(device)\n",
    "        output = net(img)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        img_id = os.path.splitext(os.path.basename(img_path))[0]#获取文件名不带扩展名\n",
    "        label_str = label_map_reverse[int(pred.item())]\n",
    "        results.append((img_id, label_str))\n",
    "#写入CSV文件\n",
    "with open(\"submission.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"label\"])#表头\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d5504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
